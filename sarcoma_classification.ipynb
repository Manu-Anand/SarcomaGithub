{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we'll import pandas, a data processing and CSV file I/O library\n",
    "import pandas as pd\n",
    "from scipy import special\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "#from matplotlib.mlab import PCA as mlabPCA\n",
    "import numpy as np\n",
    "import time\n",
    "#from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import log1p\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# We'll also import seaborn, a Python graphing library\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import hypertools as hyp\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.lda import LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reads Beta file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readBetaFile():\n",
    "    sarc_old = pd.read_csv(\"data/SARC-combined.txt\", usecols= [*range(0, 261)], index_col = 0, sep='\\t')  \n",
    "    #sarc = sarc_old.T # Transposes to have data along rows\n",
    "    sarc = sarc_old.transpose().reset_index().rename(columns={'index':'Composite_Element_REF'})\n",
    "    sarc.columns.name = None \n",
    "    print(sarc.shape)\n",
    "    #Drops columns with 'rs' features from beta file\n",
    "    sarc = sarc.drop(sarc.filter(like='rs').columns, 1)  \n",
    "    #print(sarc.shape)\n",
    "    #Drops columns with Sex probes(X and Y). Reads from manifestfile\n",
    "    #From manifest sees the column CHR and finds X or Y. If yes, return a list that changed to DF.\n",
    "    # Now make it series data of list.\n",
    "    manifest = pd.read_csv(\"data/HumanMethylation450_15017482_v1-2.csv\")\n",
    "    sex_probes_df = pd.DataFrame(manifest.loc[(manifest['CHR'] == 'X') | (manifest['CHR'] == 'Y')], columns =['IlmnID'])\n",
    "    sex_probes = sex_probes_df['IlmnID'].values.tolist()\n",
    "    sarc = sarc.drop(sarc.filter(sex_probes).columns, 1)\n",
    "    #print(sarc.shape)\n",
    "    # Drops NaN data if any are NaN (The data has almost all data value NaN for some features)\n",
    "    sarc=sarc.dropna(axis='columns',how='any')\n",
    "    #print(sarc.shape)\n",
    "    return sarc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reads MeDeCom output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readMedeComReconstructed():\n",
    "    beta_rec_old = pd.read_csv(\"data/reconstructedbeta.csv\", index_col = 0) #, usecols= [*range(0, 261)], index_col = 0')  \n",
    "    #beta = beta_rec_old.T # Transposes to have data along rows\n",
    "    beta_recon = beta_rec_old.transpose().reset_index().rename(columns={'index':'Composite_Element_REF'})\n",
    "    beta_recon.columns.name = None \n",
    "    #Drops columns with 'rs' features from beta file\n",
    "    beta_recon = beta_recon.drop(beta_recon.filter(like='rs').columns, 1)  \n",
    "    print(beta_recon.shape)\n",
    "    #Drops columns with Sex probes(X and Y). Reads from manifestfile\n",
    "    #From manifest sees the column CHR and finds X or Y. If yes, return a list that changed to DF.\n",
    "    # Now make it series data of list.\n",
    "    manifest = pd.read_csv(\"data/HumanMethylation450_15017482_v1-2.csv\")\n",
    "    sex_probes_df = pd.DataFrame(manifest.loc[(manifest['CHR'] == 'X') | (manifest['CHR'] == 'Y')], columns =['IlmnID'])\n",
    "    sex_probes = sex_probes_df['IlmnID'].values.tolist()\n",
    "    beta_recon = beta_recon.drop(beta_recon.filter(sex_probes).columns, 1)\n",
    "    print(beta_recon.shape)\n",
    "    # Drops NaN data if any are NaN (The data has almost all data value NaN for some features)\n",
    "    beta_recon=beta_recon.dropna(axis='rows',how='any')\n",
    "    print(beta_recon.shape)\n",
    "    return beta_recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Munjing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergeClinicalFile(keepall):\n",
    "    clinic = pd.read_csv(\"data/TCGA_SARC_Clinical-2.csv\", sep='\\s*,\\s*')\n",
    "    #clinic = pd.read_csv(\"dummy.csv\", sep='\\s*,\\s*')\n",
    "    clinic.rename(columns={'Composite Element REF':'Composite_Element_REF'}, inplace=True)\n",
    "    #prints index column calues\n",
    "    #print(clinic.index.values)\n",
    "    #print feature names\n",
    "    #print(list(clinic))\n",
    "    #print index values and corresponding values against the feature - \"Residual Tumor\"\n",
    "    #print(clinic.loc[: , \"residual_tumor\"])\n",
    "    # setting header to the columns of interests\n",
    "    header = [\"Composite_Element_REF\",\"residual_tumor\"]\n",
    "    # saving the index column and residual_columns data to sample.csv\n",
    "    #clinic.to_csv(\"sample.csv\", columns= header)    \n",
    "    # BEAUTIFUL - changes column values instantly, takes fist 10 values, replace . with _ and upper case\n",
    "    merge_clinic = pd.DataFrame(clinic, columns = ['Composite_Element_REF', 'residual_tumor'] )\n",
    "    #merge_clinic.to_csv(\"clinic_ID_label.csv\")\n",
    "    #merge_clinic['Composite_Element_REF'] = merge_clinic['Composite_Element_REF'].apply(lambda x: str(x)[0:12].replace('.', '_').upper())\n",
    "    #print(merge_clinic['Composite_Element_REF'])\n",
    "    #Just to see the data(not needed for project)\n",
    "    print_original = pd.DataFrame(sarcoma, columns = ['Composite_Element_REF'] )\n",
    "    #print_original.to_csv(\"original_beta.csv\")\n",
    "    if(keepall==0):\n",
    "        merge_sarcoma = pd.DataFrame(sarcoma, columns = ['Composite_Element_REF'] )\n",
    "    else:\n",
    "        print(\"HHHHHHH\")\n",
    "        merge_sarcoma = pd.DataFrame(sarcoma)\n",
    "    merge_sarcoma['Composite_Element_REF'] = merge_sarcoma['Composite_Element_REF'].apply(lambda x: str(x)[0:12].replace('-', '.').lower())\n",
    "    #Just to see the data(not needed for project)\n",
    "    analysis_sarc_data = pd.DataFrame(merge_sarcoma, columns = ['Composite_Element_REF'])\n",
    "    #analysis_sarc_data.to_csv(\"betafile_data_Ids.csv\")\n",
    "    #df3 = merge_clinic.merge(merge_sarcoma,on='Composite_Element_REF',\n",
    "                  #how='outer').dropna(subset=['residual_tumor'])\n",
    "    #compares the cloumns for identity and merges sarcoma data set with labels    \n",
    "    result = pd.merge(merge_sarcoma, merge_clinic, on='Composite_Element_REF', how='inner')\n",
    "    # Just for printing to test(not used for project)\n",
    "    analysis_data = pd.DataFrame(result, columns = ['Composite_Element_REF', 'residual_tumor'] )\n",
    "    #analysis_data.to_csv(\"id_label_not_combined.csv\")\n",
    "    #frames = [merge_clinic, merge_sarcoma]\n",
    "    #result = pd.concat(frames)\n",
    "    #result.to_csv(\"sample.csv\")\n",
    "    \n",
    "    result['residual_tumor'] = result.residual_tumor.str.replace(r'(^.*undifferentiated.*$)', 'Undifferentiated Sarcoma')\n",
    "    result['residual_tumor'] = result.residual_tumor.str.replace(r'(^.*synovial.*$)', 'Synovial Sarcoma')\n",
    "    \n",
    "    #Modify Wrong lables in clinical file\n",
    "    result.loc[result['Composite_Element_REF'] == 'tcga.hb.a3yv', 'residual_tumor'] = 'dedifferentiated liposarcoma'\n",
    "    result.loc[result['Composite_Element_REF'] == 'tcga.pc.a5dn', 'residual_tumor'] = 'dedifferentiated liposarcoma'\n",
    "    result.loc[result['Composite_Element_REF'] == 'tcga.dx.a6yz', 'residual_tumor'] = 'dedifferentiated liposarcoma'\n",
    "    result.loc[result['Composite_Element_REF'] == 'tcga.3b.a9hs', 'residual_tumor'] = 'dedifferentiated liposarcoma'\n",
    "    result.loc[result['Composite_Element_REF'] == 'tcga.dx.ab2s', 'residual_tumor'] = 'dedifferentiated liposarcoma'\n",
    "    # Drop Desmoid Tumors\n",
    "    result = result.drop(result.index[result.residual_tumor == 'desmoid tumor']) #tcga.z4.a8jb, tcga.qq.a8vd\n",
    "    result.index = range(len(result)) # Rearrange index\n",
    "    #Delete the outlier    \n",
    "    result = result.drop(result.index[result.Composite_Element_REF == 'tcga.k1.a6rt']) #tcga.k1.a6r\n",
    "    \n",
    "    result.index = range(len(result)) # Rearrange index\n",
    "    # Just for printing to test(not used for project)\n",
    "    analysis_data = pd.DataFrame(result, columns = ['Composite_Element_REF', 'residual_tumor'] )\n",
    "      \n",
    "    #analysis_data.to_csv(\"id_label_combined.csv\")\n",
    "    #Drop ID\n",
    "    result = result.drop('Composite_Element_REF', axis=1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Labels and Return Label Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encodeLabels(datavalue):\n",
    "    le.fit(datavalue['residual_tumor'])\n",
    "    datavalue['residual_tumor'] = le.transform(datavalue['residual_tumor'])\n",
    "    #labels = datavalue['residual_tumor'] # returns only labels exclusing header\n",
    "    return datavalue\n",
    "def getLabelCounts(labels):\n",
    "    df = pd.DataFrame(labels)\n",
    "    print(df.residual_tumor.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction - Chi-Square, Low variance Feature Reduction and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Univariate_ChiSquare():\n",
    "    chi_square = SelectKBest(score_func=chi2, k=20000)    \n",
    "    fit = chi_square.fit(sarcoma_X, sarcoma_Y)\n",
    "    features = fit.transform(sarcoma_X)\n",
    "    return features\n",
    "def pca_split():\n",
    "    n_sne = 50\n",
    "    pca = PCA()\n",
    "    pca.fit(sarcoma_X)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d = np.argmax(cumsum>=0.95) + 1\n",
    "    pca = PCA(n_components = 0.95)\n",
    "    pca_result = pca.fit_transform(sarcoma_X)\n",
    "    return pca_result\n",
    "def lowVarianceFeatureReduction():\n",
    "    selector = VarianceThreshold(0.09)\n",
    "    columns = sarcoma_X.columns\n",
    "    sarc_new = selector.fit_transform(sarcoma_X)\n",
    "    column_names = [columns[x] for x in selector.get_support(indices=True) if x]\n",
    "    newdata = pd.DataFrame(selector.fit_transform(sarcoma_X), columns=column_names)\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printValues():\n",
    "    # prints the index column values. Those are Ids related to the data. Not used for calculation                                           \n",
    "    print(sarc.index.values)\n",
    "    print(sarc.index)\n",
    "    # prints the values of data. Index column and column headers are ignored by default. its same as sarc. but an array.\n",
    "    print(sarc.values)\n",
    "    #print feature names except index column\n",
    "    print(list(sarc))\n",
    "def findCorr(pca_result):\n",
    "    #NumPy Array, convert to Dataframe\n",
    "    corr = pd.DataFrame(pca_result).corr(method='pearson')   \n",
    "    sns.heatmap(corr, \n",
    "        xticklabels=corr.columns.values,\n",
    "        yticklabels=corr.columns.values)\n",
    "    plt.show()\n",
    "def summaryStats(pca_result):\n",
    "    #pca_result.head() # return the first 5 rows\n",
    "    #pca_result.describe() # summary statistics, excluding NaN values\n",
    "    #pca_result.info(verbose=True, null_counts=True) # concise summary of the table\n",
    "    #pca_result.shape # shape of dataset\n",
    "    print(pca_result.skew()) # skewness for numeric columns\n",
    "    #pca_result.kurt() # unbiased kurtosis for numeric columns\n",
    "    #pca_result.get_dtype_counts() # counts of dtypes\n",
    "def plotCorrTsnePCsnLabels(nComponent):\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    sns.swarmplot(sarcoma_Y,xtsne[:,nComponent],order=[0, 1, 2, 3, 4, 5, 6])\n",
    "    plt.title('Correlation between PCs and target')\n",
    "    plt.xlabel('Target')\n",
    "    plt.ylabel('PC Value')\n",
    "    plt.show()\n",
    "#Plots desnity plot - to see the skewness\n",
    "def plotDensityTsne():\n",
    "    pd.DataFrame(xtsne).plot(kind='density', subplots=True, layout=(3,3), sharex=False)\n",
    "    plt.show()\n",
    "def printXandY():\n",
    "    print(sarcoma_X)\n",
    "    print(sarcoma_Y)\n",
    "#Plots density of mean, mad etc along data(mean and mad is of each category of cancer seperate)\n",
    "def plotDensityAlongDataOrFeat(sarcoma_with_label_codes):\n",
    "    group_by_lables = sarcoma_with_label_codes.groupby(sarcoma_with_label_codes['residual_tumor']).mad()\n",
    "    count_of_labels = sarcoma_with_label_codes[['residual_tumor']].groupby('residual_tumor').size()\n",
    "    group_by_mean = sarcoma_with_label_codes.groupby(sarcoma_with_label_codes['residual_tumor']).mean()\n",
    "    for col_id in range(1000):\n",
    "        #sns.distplot(group_by_mean.iloc[:,col_id]) #Plots along individual features\n",
    "        sns.distplot(group_by_mean.iloc[col_id]) # Plots along data\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA with t-SNE for multiple perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pcaWithTSNE():\n",
    "    n_sne = 50\n",
    "    pca = PCA()\n",
    "    pca.fit(sarcoma_X)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d = np.argmax(cumsum>=0.95) + 1\n",
    "    pca = PCA(n_components = 0.95)\n",
    "    pca_result = pca.fit_transform(sarcoma_X)\n",
    "    print(sum(pca.explained_variance_ratio_))\n",
    "    #TSNE calculation\n",
    "    \n",
    "    for i in [2,3, 4, 5, 7, 8, 10,20,30,40,50,60,70,80,90,100,200]:\n",
    "        X_tsne = TSNE(learning_rate=100, n_components=3, verbose=1, \n",
    "                  perplexity=i, n_iter=10000).fit_transform(pca_result)   \n",
    "        #Visualize tsne and pca\n",
    "        hyp.plot(X_tsne,'o', group=sarcoma_Y, legend=label_names, title = 'TSNE PLOT AFTER PCA PER %s'%i, palette=\"deep\")\n",
    "    #TSNE after Truncated SVD used in sparse data. First redude to less dimensions then tsne.\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    X_reduced = TruncatedSVD(n_components=50, random_state=0).fit_transform(sarcoma_X)\n",
    "    for j in [2,3,4,5,7,10,20,30,40,50,60,70,80,90,100,200]:\n",
    "        X_embedded = TSNE(n_components=3, perplexity=j, verbose=2, n_iter=10000).fit_transform(X_reduced)\n",
    "        hyp.plot(X_embedded,'o', group=sarcoma_Y, legend=label_names, title = 'SVD TSNE PLOT PER %s'%j, palette=\"deep\")\n",
    "    ####################\n",
    "    T_SNE = TSNE(learning_rate=100, n_components=3, verbose=1, \n",
    "                  perplexity=40, n_iter=50000).fit_transform(sarcoma_X)\n",
    "    hyp.plot(T_SNE,'o', group=sarcoma_Y, legend=label_names, title = 'TSNE OVER FULL DIMENSIONS', palette=\"deep\")\n",
    "    ##########################\n",
    "    from sklearn.manifold import MDS\n",
    "    MDS_model = MDS(n_components=3, n_jobs=-1).fit_transform(sarcoma_X)\n",
    "    hyp.plot(T_SNE,'o', group=sarcoma_Y, legend=label_names, title = 'MDS OVER FULL DIMENSIONS', palette=\"deep\")\n",
    "    return pca_result\n",
    "#Correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifaction_report_csv(report):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-3]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['cancer type'] = row_data[1]\n",
    "        row['precision'] = float(row_data[2])\n",
    "        row['recall'] = float(row_data[3])\n",
    "        row['f1_score'] = float(row_data[4])\n",
    "        row['support'] = float(row_data[5])\n",
    "        report_data.append(row)\n",
    "    dataframe = pd.DataFrame.from_dict(report_data)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_figures(data_to_plot, fileName, title):\n",
    "    #Plot params\n",
    "    plt.clf()\n",
    "    colors = ['magenta', 'cyan', 'grey', 'red', 'green', 'orange']\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    y_nump =sarcoma_Y.values\n",
    "    for color, i, target_name in zip(colors, [0, 1, 2, 3, 4, 5], label_names):\n",
    "        ax.scatter(data_to_plot[y_nump == i, 0], data_to_plot[y_nump == i, 1], alpha=.8, color=color,label=target_name)\n",
    "    \n",
    "    # Shrink current axis by 20%\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    lgd = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
    "    ax.grid('on')\n",
    "    plt.title('%s plot of Sarcoma Dataset'%title)\n",
    "    plt.savefig(fileName, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsne_scatter():\n",
    "    \n",
    "    #Pca\n",
    "    pca = PCA()\n",
    "    pca.fit(sarcoma_X)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d = np.argmax(cumsum>=0.95) + 1\n",
    "    pca = PCA(n_components = 0.95)\n",
    "    pc1 = pca.fit(sarcoma_X)\n",
    "    pca_result = pca.fit_transform(sarcoma_X)\n",
    "    print(pc1.n_components_)\n",
    "    print(pc1.explained_variance_ratio_)\n",
    "    X_tsne = TSNE(learning_rate=100, n_components=2, verbose=1, \n",
    "                  perplexity=60, n_iter=10000).fit_transform(sarcoma_X) \n",
    "    plot_figures(X_tsne, 'plots/tsne.png', 'TSNE(without PCA)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_LDA(no_of_components, type_of_cancer_label):\n",
    "    lda = LinearDiscriminantAnalysis(n_components=no_of_components)\n",
    "    lda_transformed = lda.fit_transform(sarcoma_X, sarcoma_Y)\n",
    "    plot_figures(lda_transformed, 'plots/lda.png', \"LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Chisquare with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Univariate_ChiSquare_XGBoost():\n",
    "    test = SelectKBest(score_func=chi2, k=130000)\n",
    "    \n",
    "    fit = test.fit(sarcoma_X, sarcoma_Y)\n",
    "    #numpy.set_printoptions(precision=3)\n",
    "    #print(fit.scores_)\n",
    "    features = fit.transform(sarcoma_X)\n",
    "    print(features.shape)\n",
    "    \n",
    "    seed = 7\n",
    "    \n",
    "    trainx, testx, trainy, testy = train_test_split(features, sarcoma_Y, test_size=0.3, random_state=0, stratify=sarcoma_Y)\n",
    "    \n",
    "    #fit model no training data\n",
    "    model = XGBClassifier()\n",
    "    model.fit(trainx, trainy)\n",
    "    \n",
    "    y_test_pred = model.predict(testx)    \n",
    "    cm_tst = confusion_matrix(testy, y_test_pred)\n",
    "    print(cm_tst)\n",
    "    #Plot CM for test data\n",
    "    \n",
    "    plt.clf()\n",
    "    ax = sns.heatmap(cm_tst,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    plt.savefig('chisquare_test_cf.png', bbox_inches='tight')\n",
    "    #Print accuracy report\n",
    "    report = classification_report(testy, y_test_pred)\n",
    "    df = classifaction_report_csv(report)\n",
    "    df.to_csv('chsq_report.csv', index = True)\n",
    "    print(classification_report(testy, y_test_pred))\n",
    "    print(accuracy_score(testy, y_test_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticRegressionSoftmax(pca_result, result):\n",
    "    print(pca_result)\n",
    "    \n",
    "    trainx, testx, trainy, testy = train_test_split(pca_result, sarcoma_Y, test_size=0.3, random_state=0, stratify=sarcoma_Y)\n",
    "    softmax_reg = linear_model.LogisticRegression(multi_class = \"multinomial\", solver = \"lbfgs\", C = 10)\n",
    "    softmax_reg.fit(trainx, trainy)\n",
    "    y_test_pred = softmax_reg.predict(testx)\n",
    "    accuracy = accuracy_score(testy, y_test_pred)\n",
    "        \n",
    "    cm_tst = confusion_matrix(testy, y_test_pred)\n",
    "    \n",
    "    ax = sns.heatmap(cm_tst,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    \n",
    "    plt.savefig('plots/log_reg_cm.png', bbox_inches='tight')\n",
    "    #Print accuracy report\n",
    "    report = classification_report(testy, y_test_pred)\n",
    "    df = classifaction_report_csv(report)\n",
    "    df.to_csv('plots/logregre_report.csv', index = True)\n",
    "    print(accuracy_score(testy, y_test_pred))\n",
    "    print(classification_report(testy, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_RandomForestClassifier():\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(features, sarcoma_Y, test_size=0.3, random_state=0, stratify=sarcoma_Y)\n",
    "    rfc = RandomForestClassifier(n_jobs=-1,max_features= 'auto' ,n_estimators=8000, oob_score = True)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = rfc.predict(X_train)\n",
    "    cm = confusion_matrix(y_train, y_train_pred)\n",
    "    # Plot confusion metrix against train prediction cv   \n",
    "    ax = sns.heatmap(cm,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    plt.savefig('plots/rf_train_cf.png', bbox_inches='tight')\n",
    "       \n",
    "    y_test_pred = rfc.predict(X_test)    \n",
    "    cm_tst = confusion_matrix(y_test, y_test_pred)\n",
    "    #print(cm_tst)\n",
    "    #Plot CM for test data\n",
    "    plt.clf()\n",
    "    ax = sns.heatmap(cm_tst,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    plt.savefig('plots/rf_test_cf.png', bbox_inches='tight')\n",
    "    #Print accuracy report\n",
    "    report = classification_report(y_test, y_test_pred)\n",
    "    df = classifaction_report_csv(report)\n",
    "    df.to_csv('plots/rf_report.csv', index = True)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_linearSVC():\n",
    "    #Find hyperparameter for Linear SVC based on accuracy\n",
    "    \n",
    "    svc = LinearSVC(penalty=\"l1\", dual=False) # trains 6 models of shape(_samples, n_classes)\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    C_s = np.logspace(-3, 1, 30)  #10^-3 to 10^ 1 with 10 steps. so its 0.001 to 1 \n",
    "    scores = list()\n",
    "    scores_std = list()\n",
    "    for C in C_s:\n",
    "        svc.C = C\n",
    "        #cross validation accuracy. \n",
    "        this_scores = cross_val_score(svc, X_train, y_train, cv = 4, n_jobs=1)\n",
    "        scores.append(np.mean(this_scores))\n",
    "        scores_std.append(np.std(this_scores))\n",
    "    # Do the plotting\n",
    "    plt.figure(1, figsize=(4, 3))\n",
    "    #plt.clf()\n",
    "    plt.semilogx(C_s, scores)\n",
    "    plt.semilogx(C_s, np.array(scores) + np.array(scores_std), 'b--')\n",
    "    plt.semilogx(C_s, np.array(scores) - np.array(scores_std), 'b--')\n",
    "    locs, labels = plt.yticks()\n",
    "    plt.yticks(locs, list(map(lambda x: \"%g\" % x, locs)))\n",
    "    plt.ylabel('CV score')\n",
    "    plt.xlabel('Parameter C')\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.savefig('plots/linearsvc_CV_error.png')\n",
    "    plt.show()\n",
    "    # Another way to meaure accuracy of training with cross validation, but here we took C = best. \n",
    "    # we can do the same above to find C\n",
    "    \n",
    "    plt.clf()\n",
    "    best_C = C_s[np.argmax(scores)]\n",
    "    #Just check the prediction efficiency against best C for 5 fold cross validated data\n",
    "    svc.C = best_C\n",
    "    y_train_pred = cross_val_predict(svc,X_train,y_train, cv=4)   \n",
    "    cm = confusion_matrix(y_train, y_train_pred)\n",
    "    # Plot confusion metrix against train prediction cv   \n",
    "    ax = sns.heatmap(cm,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    \n",
    "    plt.savefig('plots/linearSVC_train.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    np.fill_diagonal(cm, 0)\n",
    "    ax = sns.heatmap(cm,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    \n",
    "    plt.savefig('plots/linearSVC_train_filldiag.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    #Fit model to the train data with best C value\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_test_pred = svc.predict(X_test)\n",
    "    cm_tst = confusion_matrix(y_test, y_test_pred)\n",
    "    print(cm_tst)\n",
    "    #Plot CM for test data\n",
    "    ax = sns.heatmap(cm_tst,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    \n",
    "    plt.savefig('plots/linearSVC_test.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    np.fill_diagonal(cm_tst, 0)\n",
    "    ax = sns.heatmap(cm_tst,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    \n",
    "    plt.savefig('plots/linearSVC_test_filldiag.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    #Print accuracy report\n",
    "    report = classification_report(y_test, y_test_pred)\n",
    "    df = classifaction_report_csv(report)\n",
    "    df.to_csv('plots/linearSVC_report.csv', index = True)\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(accuracy_score(y_test, y_test_pred))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyXGBoost():\n",
    "    seed = 7\n",
    "    #fit model no training data\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    cm = confusion_matrix(y_train, y_train_pred)\n",
    "    # Plot confusion metrix against train prediction cv   \n",
    "    ax = sns.heatmap(cm,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    plt.savefig('plots/xgboost_train_cf.png', bbox_inches='tight')\n",
    "    \n",
    "    plt.clf()\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_test_pred]\n",
    "    #evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))    \n",
    "    cm_tst = confusion_matrix(y_test, y_test_pred)\n",
    "    #Plot CM for test data\n",
    "    \n",
    "    ax = sns.heatmap(cm_tst,annot=True, xticklabels=label_names, yticklabels=label_names)\n",
    "    ax.set_ylabel('Actual classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    \n",
    "    plt.savefig('plots/xgboost_test_cf.png', bbox_inches='tight')\n",
    "    #Print accuracy report\n",
    "    report = classification_report(y_test, y_test_pred)\n",
    "    df = classifaction_report_csv(report)\n",
    "    df.to_csv('plots/xgboost_report.csv', index = True)\n",
    "    print(accuracy_score(y_test, y_test_pred))\n",
    "    print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section contains function calls.\n",
    "This section deals with different function calls already defined. It reads the betafile, combines it with clinical file labels, does data munging using manifest file to remove sex probes and rs probes, removing nulls, deleting desmoid tumor, relabelling misclassified lables etc and finally splitting the combined file to sarcoma_X and sarcoma_Y as data and target label files for classification. This section contains the following\n",
    "1. Dimensionality reduction with PCA/Chi-Square/Low variance feature reduction and Classify with Logistic Regression and Linear SVC\n",
    "2. Embedded classification with Linear SVC with l1 regularization, Random Forest, XG Boost\n",
    "3. data Visualization with t-SNE, LDA, PCA-TSNE\n",
    "4. MeDeCom - with steps 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reads beta file\n",
    "sarcoma = readBetaFile()\n",
    "\n",
    "#Reads reconstructed MedCom file. Uncomment this line and comment above line to use the MeDeCom csv file.\n",
    "#sarcoma = readMedeComReconstructed()\n",
    "\n",
    "#Result dataframe contains only label data if parameter passed is 0. else it returns a dataframe with whole data\n",
    "#merged with labels. Default use 1.\n",
    "sarcoma_with_label_names = mergeClinicalFile(1)\n",
    "#print(getLabelCounts(sarcoma_with_label_names)) # Good one to show no of labels for each\n",
    "\n",
    "#Returns Encoded labels\n",
    "le = LabelEncoder()\n",
    "sarcoma_with_label_codes = encodeLabels(sarcoma_with_label_names)\n",
    "\n",
    "#Reuturns label names corresponds to each label code. \n",
    "label_names = list(le.inverse_transform([0, 1, 2, 3, 4, 5]))\n",
    "\n",
    "#Target labels for classification\n",
    "sarcoma_Y= sarcoma_with_label_codes['residual_tumor']\n",
    "#Data for classification\n",
    "sarcoma_X = sarcoma_with_label_codes.drop('residual_tumor', axis=1)\n",
    "print(sarcoma_X.shape)\n",
    "#Not used. Can be experimented later to normalize with unit variance and zero mean and Logit tranformation.\n",
    "sarcoma_X_scale = scale(sarcoma_X)\n",
    "sarcoma_M_X = special.logit(sarcoma_X)\n",
    "\n",
    "#Splits data to train and test to use for classifiers\n",
    "X_train, X_test, y_train, y_test = train_test_split(sarcoma_X, sarcoma_Y, test_size=0.3, random_state=0, stratify=sarcoma_Y)\n",
    "\n",
    "#Prints label counts for each group\n",
    "getLabelCounts(sarcoma_Y)\n",
    "\n",
    "#Feature Selection with Chisquare/PCA/Low variance reduction\n",
    "#Uncomment to use as required. Use nay feature reduction and call logisticRegressionSoftmax()\n",
    "#Ise with original beta file, never with MeDeCom output\n",
    "#pca_result = pca_split() # Use with LogisticRegressionSoftmax()\n",
    "#features = Univariate_ChiSquare() # Use with LogisticRegressionSoftmax()\n",
    "#features = lowVarianceFeatureReduction() # Use with LogisticRegressionSoftmax()\n",
    "#logisticRegressionSoftmax(features, sarcoma_Y)\n",
    "\n",
    "#2 is no of components, 7 means plots all labels else plots specific type of cancer only. \n",
    "#Use 1 to 6 for each cancet types\n",
    "classify_LDA(2, 7) \n",
    "tsne_scatter()\n",
    "classify_linearSVC()# 71.25 with medecom\n",
    "classify_RandomForestClassifier() #77.5% with medecom and n_estimators 8000(>5000)\n",
    "classifyXGBoost() #  72.5 with medecom\n",
    "\n",
    "#Not used but can be experimented.\n",
    "#classify_linearSGD()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Functions for summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use only when we use feature selection algorithms for SVC\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, sarcoma_Y, test_size=0.3, random_state=0, stratify=sarcoma_Y)\n",
    "#classify_linearSVC()\n",
    "\n",
    "#Different plots\n",
    "#printXandY()\n",
    "#pcaWithFixedComp(10000)\n",
    "#summaryStats(pd.DataFrame(pca_result))\n",
    "#plotDensityTsne()\n",
    "#plotCorrTsnePCsnLabels(0)\n",
    "#plotCorrTsnePCsnLabels(1)\n",
    "#plotCorrTsnePCsnLabels(2)\n",
    "#sns.violinplot(sarcoma_data.iloc[0], color = 'cyan')\n",
    "#plt.show()\n",
    "#findCorr(pca_result) \n",
    "#plotDensityAlongDataOrFeat(sarcoma_with_label_codes)\n",
    "#classify_RF_PCA(10000)\n",
    "#classify_LDA_Test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
